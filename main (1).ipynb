{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d23c7e3a-74c3-458a-a4f9-30ebff580d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "540017f7-2e00-4ef5-9c96-908871f42e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:00<00:00, 10924934.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 64433879.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:00<00:00, 3777315.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 6102027.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_data=datasets.MNIST(root='data', train=True,transform=ToTensor(),download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b128bd37-e503-4215-8f68-d439803644d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data=datasets.MNIST(root='data', train=True,transform=ToTensor(),download=True)\n",
    "test_data=datasets.MNIST(root='data', train=False,transform=ToTensor(),download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98b07fab-9fd3-406a-97c2-8b67b8c700c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8ee95c6-76fd-4712-b939-249265d2cc53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 10000\n",
       "    Root location: data\n",
       "    Split: Test\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f99cabf1-84b4-4fbf-b756-2ab19bee3408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.data.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc4ba1d6-6c72-43b1-9955-abdd290961fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f26be818-f960-4dc2-82aa-039b33ccf92f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.targets.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00d20aff-55da-40aa-aa76-1c7503080e55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 0, 4,  ..., 5, 6, 8])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "13458d0b-c487-482c-9f76-9fed7a5aa576",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "loaders={'train': DataLoader(train_data, batch_size=100,shuffle=True, num_workers=1),\n",
    "         'test': DataLoader(test_data,batch_size=100,shuffle=True,num_workers=1),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64745f16-3814-4cad-99ec-9e19faee7cf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': <torch.utils.data.dataloader.DataLoader at 0x14edd7b50>,\n",
       " 'test': <torch.utils.data.dataloader.DataLoader at 0x168e81790>}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "22f59220-9de8-4112-8a62-2b6809971520",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "\n",
    "        self.convl=nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2=nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop=nn.Dropout2d()\n",
    "        self.fc1=nn.Linear(320, 50)\n",
    "        self.fc2=nn.Linear(50,10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.convl(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "    \n",
    "        return F.softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2c90ec57-37a5-4945-9667-9dc0c7f84a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = CNN().to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(loaders['train']):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = loss_fn(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 20 == 0:\n",
    "            print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(loaders[\"train\"].dataset)} ({100. * batch_idx / len(loaders[\"train\"]):.0f}%)]\\tLoss: {loss.item():.6f}')\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    \n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in loaders['test']:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += loss_fn(output, target).item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(loaders['test'].dataset)\n",
    "    print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(loaders[\"test\"].dataset)} ({100. * correct / len(loaders[\"test\"].dataset):.0f}%)\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9c53f2d1-d24b-447d-87c9-2623fdc1e6b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.304305\n",
      "Train Epoch: 1 [2000/60000 (3%)]\tLoss: 2.295123\n",
      "Train Epoch: 1 [4000/60000 (7%)]\tLoss: 2.255846\n",
      "Train Epoch: 1 [6000/60000 (10%)]\tLoss: 2.125864\n",
      "Train Epoch: 1 [8000/60000 (13%)]\tLoss: 1.977289\n",
      "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 1.842357\n",
      "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 1.801282\n",
      "Train Epoch: 1 [14000/60000 (23%)]\tLoss: 1.753541\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 1.846059\n",
      "Train Epoch: 1 [18000/60000 (30%)]\tLoss: 1.696830\n",
      "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 1.677013\n",
      "Train Epoch: 1 [22000/60000 (37%)]\tLoss: 1.686129\n",
      "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 1.754299\n",
      "Train Epoch: 1 [26000/60000 (43%)]\tLoss: 1.714993\n",
      "Train Epoch: 1 [28000/60000 (47%)]\tLoss: 1.617994\n",
      "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 1.676015\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 1.662539\n",
      "Train Epoch: 1 [34000/60000 (57%)]\tLoss: 1.627555\n",
      "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 1.653570\n",
      "Train Epoch: 1 [38000/60000 (63%)]\tLoss: 1.651403\n",
      "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 1.622705\n",
      "Train Epoch: 1 [42000/60000 (70%)]\tLoss: 1.635298\n",
      "Train Epoch: 1 [44000/60000 (73%)]\tLoss: 1.615037\n",
      "Train Epoch: 1 [46000/60000 (77%)]\tLoss: 1.651487\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 1.596547\n",
      "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 1.623545\n",
      "Train Epoch: 1 [52000/60000 (87%)]\tLoss: 1.589926\n",
      "Train Epoch: 1 [54000/60000 (90%)]\tLoss: 1.606763\n",
      "Train Epoch: 1 [56000/60000 (93%)]\tLoss: 1.614390\n",
      "Train Epoch: 1 [58000/60000 (97%)]\tLoss: 1.624961\n",
      "\n",
      "Test set: Average loss: 0.0153, Accuracy: 9287/10000 (93%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 1.617834\n",
      "Train Epoch: 2 [2000/60000 (3%)]\tLoss: 1.615329\n",
      "Train Epoch: 2 [4000/60000 (7%)]\tLoss: 1.633649\n",
      "Train Epoch: 2 [6000/60000 (10%)]\tLoss: 1.588566\n",
      "Train Epoch: 2 [8000/60000 (13%)]\tLoss: 1.601459\n",
      "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 1.555988\n",
      "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 1.594000\n",
      "Train Epoch: 2 [14000/60000 (23%)]\tLoss: 1.606236\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 1.599488\n",
      "Train Epoch: 2 [18000/60000 (30%)]\tLoss: 1.558726\n",
      "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 1.593046\n",
      "Train Epoch: 2 [22000/60000 (37%)]\tLoss: 1.586898\n",
      "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 1.566848\n",
      "Train Epoch: 2 [26000/60000 (43%)]\tLoss: 1.588813\n",
      "Train Epoch: 2 [28000/60000 (47%)]\tLoss: 1.522514\n",
      "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 1.593321\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 1.570526\n",
      "Train Epoch: 2 [34000/60000 (57%)]\tLoss: 1.541667\n",
      "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 1.556881\n",
      "Train Epoch: 2 [38000/60000 (63%)]\tLoss: 1.601840\n",
      "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 1.541409\n",
      "Train Epoch: 2 [42000/60000 (70%)]\tLoss: 1.607803\n",
      "Train Epoch: 2 [44000/60000 (73%)]\tLoss: 1.550419\n",
      "Train Epoch: 2 [46000/60000 (77%)]\tLoss: 1.557341\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 1.564070\n",
      "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 1.638712\n",
      "Train Epoch: 2 [52000/60000 (87%)]\tLoss: 1.563248\n",
      "Train Epoch: 2 [54000/60000 (90%)]\tLoss: 1.610630\n",
      "Train Epoch: 2 [56000/60000 (93%)]\tLoss: 1.566530\n",
      "Train Epoch: 2 [58000/60000 (97%)]\tLoss: 1.540049\n",
      "\n",
      "Test set: Average loss: 0.0151, Accuracy: 9536/10000 (95%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 1.559407\n",
      "Train Epoch: 3 [2000/60000 (3%)]\tLoss: 1.557362\n",
      "Train Epoch: 3 [4000/60000 (7%)]\tLoss: 1.530297\n",
      "Train Epoch: 3 [6000/60000 (10%)]\tLoss: 1.593407\n",
      "Train Epoch: 3 [8000/60000 (13%)]\tLoss: 1.550596\n",
      "Train Epoch: 3 [10000/60000 (17%)]\tLoss: 1.577817\n",
      "Train Epoch: 3 [12000/60000 (20%)]\tLoss: 1.604575\n",
      "Train Epoch: 3 [14000/60000 (23%)]\tLoss: 1.555100\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 1.540523\n",
      "Train Epoch: 3 [18000/60000 (30%)]\tLoss: 1.536398\n",
      "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 1.548104\n",
      "Train Epoch: 3 [22000/60000 (37%)]\tLoss: 1.606757\n",
      "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 1.555504\n",
      "Train Epoch: 3 [26000/60000 (43%)]\tLoss: 1.572529\n",
      "Train Epoch: 3 [28000/60000 (47%)]\tLoss: 1.582257\n",
      "Train Epoch: 3 [30000/60000 (50%)]\tLoss: 1.505336\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 1.525329\n",
      "Train Epoch: 3 [34000/60000 (57%)]\tLoss: 1.554816\n",
      "Train Epoch: 3 [36000/60000 (60%)]\tLoss: 1.571408\n",
      "Train Epoch: 3 [38000/60000 (63%)]\tLoss: 1.601449\n",
      "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 1.530015\n",
      "Train Epoch: 3 [42000/60000 (70%)]\tLoss: 1.538845\n",
      "Train Epoch: 3 [44000/60000 (73%)]\tLoss: 1.574122\n",
      "Train Epoch: 3 [46000/60000 (77%)]\tLoss: 1.561859\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 1.559803\n",
      "Train Epoch: 3 [50000/60000 (83%)]\tLoss: 1.541702\n",
      "Train Epoch: 3 [52000/60000 (87%)]\tLoss: 1.581133\n",
      "Train Epoch: 3 [54000/60000 (90%)]\tLoss: 1.553131\n",
      "Train Epoch: 3 [56000/60000 (93%)]\tLoss: 1.585426\n",
      "Train Epoch: 3 [58000/60000 (97%)]\tLoss: 1.511185\n",
      "\n",
      "Test set: Average loss: 0.0150, Accuracy: 9591/10000 (96%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 1.551060\n",
      "Train Epoch: 4 [2000/60000 (3%)]\tLoss: 1.569063\n",
      "Train Epoch: 4 [4000/60000 (7%)]\tLoss: 1.542547\n",
      "Train Epoch: 4 [6000/60000 (10%)]\tLoss: 1.553191\n",
      "Train Epoch: 4 [8000/60000 (13%)]\tLoss: 1.537487\n",
      "Train Epoch: 4 [10000/60000 (17%)]\tLoss: 1.580738\n",
      "Train Epoch: 4 [12000/60000 (20%)]\tLoss: 1.557013\n",
      "Train Epoch: 4 [14000/60000 (23%)]\tLoss: 1.538599\n",
      "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 1.574766\n",
      "Train Epoch: 4 [18000/60000 (30%)]\tLoss: 1.558993\n",
      "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 1.607023\n",
      "Train Epoch: 4 [22000/60000 (37%)]\tLoss: 1.557603\n",
      "Train Epoch: 4 [24000/60000 (40%)]\tLoss: 1.555079\n",
      "Train Epoch: 4 [26000/60000 (43%)]\tLoss: 1.547795\n",
      "Train Epoch: 4 [28000/60000 (47%)]\tLoss: 1.590359\n",
      "Train Epoch: 4 [30000/60000 (50%)]\tLoss: 1.565006\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 1.552869\n",
      "Train Epoch: 4 [34000/60000 (57%)]\tLoss: 1.531891\n",
      "Train Epoch: 4 [36000/60000 (60%)]\tLoss: 1.533678\n",
      "Train Epoch: 4 [38000/60000 (63%)]\tLoss: 1.514405\n",
      "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 1.534315\n",
      "Train Epoch: 4 [42000/60000 (70%)]\tLoss: 1.514521\n",
      "Train Epoch: 4 [44000/60000 (73%)]\tLoss: 1.569477\n",
      "Train Epoch: 4 [46000/60000 (77%)]\tLoss: 1.526634\n",
      "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 1.540335\n",
      "Train Epoch: 4 [50000/60000 (83%)]\tLoss: 1.533790\n",
      "Train Epoch: 4 [52000/60000 (87%)]\tLoss: 1.586446\n",
      "Train Epoch: 4 [54000/60000 (90%)]\tLoss: 1.565008\n",
      "Train Epoch: 4 [56000/60000 (93%)]\tLoss: 1.526925\n",
      "Train Epoch: 4 [58000/60000 (97%)]\tLoss: 1.555023\n",
      "\n",
      "Test set: Average loss: 0.0150, Accuracy: 9615/10000 (96%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 1.546075\n",
      "Train Epoch: 5 [2000/60000 (3%)]\tLoss: 1.499949\n",
      "Train Epoch: 5 [4000/60000 (7%)]\tLoss: 1.544792\n",
      "Train Epoch: 5 [6000/60000 (10%)]\tLoss: 1.563263\n",
      "Train Epoch: 5 [8000/60000 (13%)]\tLoss: 1.544685\n",
      "Train Epoch: 5 [10000/60000 (17%)]\tLoss: 1.536214\n",
      "Train Epoch: 5 [12000/60000 (20%)]\tLoss: 1.565725\n",
      "Train Epoch: 5 [14000/60000 (23%)]\tLoss: 1.539410\n",
      "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 1.584593\n",
      "Train Epoch: 5 [18000/60000 (30%)]\tLoss: 1.550846\n",
      "Train Epoch: 5 [20000/60000 (33%)]\tLoss: 1.521134\n",
      "Train Epoch: 5 [22000/60000 (37%)]\tLoss: 1.492531\n",
      "Train Epoch: 5 [24000/60000 (40%)]\tLoss: 1.651601\n",
      "Train Epoch: 5 [26000/60000 (43%)]\tLoss: 1.575777\n",
      "Train Epoch: 5 [28000/60000 (47%)]\tLoss: 1.563855\n",
      "Train Epoch: 5 [30000/60000 (50%)]\tLoss: 1.562640\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 1.538714\n",
      "Train Epoch: 5 [34000/60000 (57%)]\tLoss: 1.551680\n",
      "Train Epoch: 5 [36000/60000 (60%)]\tLoss: 1.515406\n",
      "Train Epoch: 5 [38000/60000 (63%)]\tLoss: 1.558697\n",
      "Train Epoch: 5 [40000/60000 (67%)]\tLoss: 1.571861\n",
      "Train Epoch: 5 [42000/60000 (70%)]\tLoss: 1.527143\n",
      "Train Epoch: 5 [44000/60000 (73%)]\tLoss: 1.520296\n",
      "Train Epoch: 5 [46000/60000 (77%)]\tLoss: 1.529732\n",
      "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 1.553603\n",
      "Train Epoch: 5 [50000/60000 (83%)]\tLoss: 1.539308\n",
      "Train Epoch: 5 [52000/60000 (87%)]\tLoss: 1.534762\n",
      "Train Epoch: 5 [54000/60000 (90%)]\tLoss: 1.513986\n",
      "Train Epoch: 5 [56000/60000 (93%)]\tLoss: 1.527716\n",
      "Train Epoch: 5 [58000/60000 (97%)]\tLoss: 1.550204\n",
      "\n",
      "Test set: Average loss: 0.0150, Accuracy: 9642/10000 (96%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 1.543661\n",
      "Train Epoch: 6 [2000/60000 (3%)]\tLoss: 1.509408\n",
      "Train Epoch: 6 [4000/60000 (7%)]\tLoss: 1.529002\n",
      "Train Epoch: 6 [6000/60000 (10%)]\tLoss: 1.540980\n",
      "Train Epoch: 6 [8000/60000 (13%)]\tLoss: 1.526772\n",
      "Train Epoch: 6 [10000/60000 (17%)]\tLoss: 1.530189\n",
      "Train Epoch: 6 [12000/60000 (20%)]\tLoss: 1.556685\n",
      "Train Epoch: 6 [14000/60000 (23%)]\tLoss: 1.533819\n",
      "Train Epoch: 6 [16000/60000 (27%)]\tLoss: 1.540866\n",
      "Train Epoch: 6 [18000/60000 (30%)]\tLoss: 1.556355\n",
      "Train Epoch: 6 [20000/60000 (33%)]\tLoss: 1.552046\n",
      "Train Epoch: 6 [22000/60000 (37%)]\tLoss: 1.506668\n",
      "Train Epoch: 6 [24000/60000 (40%)]\tLoss: 1.569471\n",
      "Train Epoch: 6 [26000/60000 (43%)]\tLoss: 1.582994\n",
      "Train Epoch: 6 [28000/60000 (47%)]\tLoss: 1.553352\n",
      "Train Epoch: 6 [30000/60000 (50%)]\tLoss: 1.531649\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 1.575443\n",
      "Train Epoch: 6 [34000/60000 (57%)]\tLoss: 1.537659\n",
      "Train Epoch: 6 [36000/60000 (60%)]\tLoss: 1.552976\n",
      "Train Epoch: 6 [38000/60000 (63%)]\tLoss: 1.556116\n",
      "Train Epoch: 6 [40000/60000 (67%)]\tLoss: 1.570262\n",
      "Train Epoch: 6 [42000/60000 (70%)]\tLoss: 1.515862\n",
      "Train Epoch: 6 [44000/60000 (73%)]\tLoss: 1.536724\n",
      "Train Epoch: 6 [46000/60000 (77%)]\tLoss: 1.584373\n",
      "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 1.528692\n",
      "Train Epoch: 6 [50000/60000 (83%)]\tLoss: 1.540808\n",
      "Train Epoch: 6 [52000/60000 (87%)]\tLoss: 1.502453\n",
      "Train Epoch: 6 [54000/60000 (90%)]\tLoss: 1.601017\n",
      "Train Epoch: 6 [56000/60000 (93%)]\tLoss: 1.556543\n",
      "Train Epoch: 6 [58000/60000 (97%)]\tLoss: 1.515945\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy: 9668/10000 (97%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 1.516322\n",
      "Train Epoch: 7 [2000/60000 (3%)]\tLoss: 1.526469\n",
      "Train Epoch: 7 [4000/60000 (7%)]\tLoss: 1.518051\n",
      "Train Epoch: 7 [6000/60000 (10%)]\tLoss: 1.551098\n",
      "Train Epoch: 7 [8000/60000 (13%)]\tLoss: 1.568565\n",
      "Train Epoch: 7 [10000/60000 (17%)]\tLoss: 1.543159\n",
      "Train Epoch: 7 [12000/60000 (20%)]\tLoss: 1.515868\n",
      "Train Epoch: 7 [14000/60000 (23%)]\tLoss: 1.521289\n",
      "Train Epoch: 7 [16000/60000 (27%)]\tLoss: 1.528102\n",
      "Train Epoch: 7 [18000/60000 (30%)]\tLoss: 1.533285\n",
      "Train Epoch: 7 [20000/60000 (33%)]\tLoss: 1.555603\n",
      "Train Epoch: 7 [22000/60000 (37%)]\tLoss: 1.534137\n",
      "Train Epoch: 7 [24000/60000 (40%)]\tLoss: 1.555596\n",
      "Train Epoch: 7 [26000/60000 (43%)]\tLoss: 1.539835\n",
      "Train Epoch: 7 [28000/60000 (47%)]\tLoss: 1.537573\n",
      "Train Epoch: 7 [30000/60000 (50%)]\tLoss: 1.538690\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 1.546186\n",
      "Train Epoch: 7 [34000/60000 (57%)]\tLoss: 1.517911\n",
      "Train Epoch: 7 [36000/60000 (60%)]\tLoss: 1.499873\n",
      "Train Epoch: 7 [38000/60000 (63%)]\tLoss: 1.565154\n",
      "Train Epoch: 7 [40000/60000 (67%)]\tLoss: 1.515266\n",
      "Train Epoch: 7 [42000/60000 (70%)]\tLoss: 1.498193\n",
      "Train Epoch: 7 [44000/60000 (73%)]\tLoss: 1.494172\n",
      "Train Epoch: 7 [46000/60000 (77%)]\tLoss: 1.532492\n",
      "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 1.502618\n",
      "Train Epoch: 7 [50000/60000 (83%)]\tLoss: 1.529417\n",
      "Train Epoch: 7 [52000/60000 (87%)]\tLoss: 1.499558\n",
      "Train Epoch: 7 [54000/60000 (90%)]\tLoss: 1.520791\n",
      "Train Epoch: 7 [56000/60000 (93%)]\tLoss: 1.532067\n",
      "Train Epoch: 7 [58000/60000 (97%)]\tLoss: 1.591210\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy: 9693/10000 (97%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 1.524107\n",
      "Train Epoch: 8 [2000/60000 (3%)]\tLoss: 1.545490\n",
      "Train Epoch: 8 [4000/60000 (7%)]\tLoss: 1.550560\n",
      "Train Epoch: 8 [6000/60000 (10%)]\tLoss: 1.507068\n",
      "Train Epoch: 8 [8000/60000 (13%)]\tLoss: 1.571301\n",
      "Train Epoch: 8 [10000/60000 (17%)]\tLoss: 1.506034\n",
      "Train Epoch: 8 [12000/60000 (20%)]\tLoss: 1.562432\n",
      "Train Epoch: 8 [14000/60000 (23%)]\tLoss: 1.546058\n",
      "Train Epoch: 8 [16000/60000 (27%)]\tLoss: 1.520122\n",
      "Train Epoch: 8 [18000/60000 (30%)]\tLoss: 1.516707\n",
      "Train Epoch: 8 [20000/60000 (33%)]\tLoss: 1.501463\n",
      "Train Epoch: 8 [22000/60000 (37%)]\tLoss: 1.511091\n",
      "Train Epoch: 8 [24000/60000 (40%)]\tLoss: 1.580333\n",
      "Train Epoch: 8 [26000/60000 (43%)]\tLoss: 1.541680\n",
      "Train Epoch: 8 [28000/60000 (47%)]\tLoss: 1.518991\n",
      "Train Epoch: 8 [30000/60000 (50%)]\tLoss: 1.514726\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 1.508065\n",
      "Train Epoch: 8 [34000/60000 (57%)]\tLoss: 1.548378\n",
      "Train Epoch: 8 [36000/60000 (60%)]\tLoss: 1.548186\n",
      "Train Epoch: 8 [38000/60000 (63%)]\tLoss: 1.521569\n",
      "Train Epoch: 8 [40000/60000 (67%)]\tLoss: 1.547827\n",
      "Train Epoch: 8 [42000/60000 (70%)]\tLoss: 1.493873\n",
      "Train Epoch: 8 [44000/60000 (73%)]\tLoss: 1.535637\n",
      "Train Epoch: 8 [46000/60000 (77%)]\tLoss: 1.536239\n",
      "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 1.528004\n",
      "Train Epoch: 8 [50000/60000 (83%)]\tLoss: 1.511253\n",
      "Train Epoch: 8 [52000/60000 (87%)]\tLoss: 1.523138\n",
      "Train Epoch: 8 [54000/60000 (90%)]\tLoss: 1.540108\n",
      "Train Epoch: 8 [56000/60000 (93%)]\tLoss: 1.542789\n",
      "Train Epoch: 8 [58000/60000 (97%)]\tLoss: 1.537189\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy: 9710/10000 (97%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 1.570095\n",
      "Train Epoch: 9 [2000/60000 (3%)]\tLoss: 1.504292\n",
      "Train Epoch: 9 [4000/60000 (7%)]\tLoss: 1.534417\n",
      "Train Epoch: 9 [6000/60000 (10%)]\tLoss: 1.548633\n",
      "Train Epoch: 9 [8000/60000 (13%)]\tLoss: 1.525671\n",
      "Train Epoch: 9 [10000/60000 (17%)]\tLoss: 1.535889\n",
      "Train Epoch: 9 [12000/60000 (20%)]\tLoss: 1.504324\n",
      "Train Epoch: 9 [14000/60000 (23%)]\tLoss: 1.497850\n",
      "Train Epoch: 9 [16000/60000 (27%)]\tLoss: 1.536052\n",
      "Train Epoch: 9 [18000/60000 (30%)]\tLoss: 1.576003\n",
      "Train Epoch: 9 [20000/60000 (33%)]\tLoss: 1.490567\n",
      "Train Epoch: 9 [22000/60000 (37%)]\tLoss: 1.551135\n",
      "Train Epoch: 9 [24000/60000 (40%)]\tLoss: 1.534604\n",
      "Train Epoch: 9 [26000/60000 (43%)]\tLoss: 1.543281\n",
      "Train Epoch: 9 [28000/60000 (47%)]\tLoss: 1.526828\n",
      "Train Epoch: 9 [30000/60000 (50%)]\tLoss: 1.530357\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 1.529168\n",
      "Train Epoch: 9 [34000/60000 (57%)]\tLoss: 1.502916\n",
      "Train Epoch: 9 [36000/60000 (60%)]\tLoss: 1.549683\n",
      "Train Epoch: 9 [38000/60000 (63%)]\tLoss: 1.504823\n",
      "Train Epoch: 9 [40000/60000 (67%)]\tLoss: 1.529936\n",
      "Train Epoch: 9 [42000/60000 (70%)]\tLoss: 1.585470\n",
      "Train Epoch: 9 [44000/60000 (73%)]\tLoss: 1.534252\n",
      "Train Epoch: 9 [46000/60000 (77%)]\tLoss: 1.511673\n",
      "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 1.540163\n",
      "Train Epoch: 9 [50000/60000 (83%)]\tLoss: 1.538971\n",
      "Train Epoch: 9 [52000/60000 (87%)]\tLoss: 1.494927\n",
      "Train Epoch: 9 [54000/60000 (90%)]\tLoss: 1.527741\n",
      "Train Epoch: 9 [56000/60000 (93%)]\tLoss: 1.492569\n",
      "Train Epoch: 9 [58000/60000 (97%)]\tLoss: 1.537072\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy: 9705/10000 (97%)\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 1.581835\n",
      "Train Epoch: 10 [2000/60000 (3%)]\tLoss: 1.544121\n",
      "Train Epoch: 10 [4000/60000 (7%)]\tLoss: 1.473658\n",
      "Train Epoch: 10 [6000/60000 (10%)]\tLoss: 1.534089\n",
      "Train Epoch: 10 [8000/60000 (13%)]\tLoss: 1.561002\n",
      "Train Epoch: 10 [10000/60000 (17%)]\tLoss: 1.493859\n",
      "Train Epoch: 10 [12000/60000 (20%)]\tLoss: 1.493047\n",
      "Train Epoch: 10 [14000/60000 (23%)]\tLoss: 1.536466\n",
      "Train Epoch: 10 [16000/60000 (27%)]\tLoss: 1.496829\n",
      "Train Epoch: 10 [18000/60000 (30%)]\tLoss: 1.536934\n",
      "Train Epoch: 10 [20000/60000 (33%)]\tLoss: 1.528634\n",
      "Train Epoch: 10 [22000/60000 (37%)]\tLoss: 1.556593\n",
      "Train Epoch: 10 [24000/60000 (40%)]\tLoss: 1.513517\n",
      "Train Epoch: 10 [26000/60000 (43%)]\tLoss: 1.536051\n",
      "Train Epoch: 10 [28000/60000 (47%)]\tLoss: 1.536995\n",
      "Train Epoch: 10 [30000/60000 (50%)]\tLoss: 1.495510\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 1.518808\n",
      "Train Epoch: 10 [34000/60000 (57%)]\tLoss: 1.518098\n",
      "Train Epoch: 10 [36000/60000 (60%)]\tLoss: 1.562983\n",
      "Train Epoch: 10 [38000/60000 (63%)]\tLoss: 1.538573\n",
      "Train Epoch: 10 [40000/60000 (67%)]\tLoss: 1.537231\n",
      "Train Epoch: 10 [42000/60000 (70%)]\tLoss: 1.511584\n",
      "Train Epoch: 10 [44000/60000 (73%)]\tLoss: 1.535200\n",
      "Train Epoch: 10 [46000/60000 (77%)]\tLoss: 1.496237\n",
      "Train Epoch: 10 [48000/60000 (80%)]\tLoss: 1.529435\n",
      "Train Epoch: 10 [50000/60000 (83%)]\tLoss: 1.524975\n",
      "Train Epoch: 10 [52000/60000 (87%)]\tLoss: 1.540417\n",
      "Train Epoch: 10 [54000/60000 (90%)]\tLoss: 1.511860\n",
      "Train Epoch: 10 [56000/60000 (93%)]\tLoss: 1.569724\n",
      "Train Epoch: 10 [58000/60000 (97%)]\tLoss: 1.544958\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy: 9719/10000 (97%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 11):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c2d27d1a-86d7-44bc-9da2-85fa0a6e40a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3a81c957-c9b7-4aeb-9a95-bf704d568faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 7\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Invalid shape (1, 28, 28) for image data",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrediction: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprediction\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      9\u001b[0m image \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m---> 10\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(image, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgray\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     11\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[0;32m~/anaconda3/envs/AI_Navigator/lib/python3.11/site-packages/matplotlib/pyplot.py:3358\u001b[0m, in \u001b[0;36mimshow\u001b[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, data, **kwargs)\u001b[0m\n\u001b[1;32m   3337\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mimshow)\n\u001b[1;32m   3338\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mimshow\u001b[39m(\n\u001b[1;32m   3339\u001b[0m     X: ArrayLike \u001b[38;5;241m|\u001b[39m PIL\u001b[38;5;241m.\u001b[39mImage\u001b[38;5;241m.\u001b[39mImage,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3356\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3357\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m AxesImage:\n\u001b[0;32m-> 3358\u001b[0m     __ret \u001b[38;5;241m=\u001b[39m gca()\u001b[38;5;241m.\u001b[39mimshow(\n\u001b[1;32m   3359\u001b[0m         X,\n\u001b[1;32m   3360\u001b[0m         cmap\u001b[38;5;241m=\u001b[39mcmap,\n\u001b[1;32m   3361\u001b[0m         norm\u001b[38;5;241m=\u001b[39mnorm,\n\u001b[1;32m   3362\u001b[0m         aspect\u001b[38;5;241m=\u001b[39maspect,\n\u001b[1;32m   3363\u001b[0m         interpolation\u001b[38;5;241m=\u001b[39minterpolation,\n\u001b[1;32m   3364\u001b[0m         alpha\u001b[38;5;241m=\u001b[39malpha,\n\u001b[1;32m   3365\u001b[0m         vmin\u001b[38;5;241m=\u001b[39mvmin,\n\u001b[1;32m   3366\u001b[0m         vmax\u001b[38;5;241m=\u001b[39mvmax,\n\u001b[1;32m   3367\u001b[0m         origin\u001b[38;5;241m=\u001b[39morigin,\n\u001b[1;32m   3368\u001b[0m         extent\u001b[38;5;241m=\u001b[39mextent,\n\u001b[1;32m   3369\u001b[0m         interpolation_stage\u001b[38;5;241m=\u001b[39minterpolation_stage,\n\u001b[1;32m   3370\u001b[0m         filternorm\u001b[38;5;241m=\u001b[39mfilternorm,\n\u001b[1;32m   3371\u001b[0m         filterrad\u001b[38;5;241m=\u001b[39mfilterrad,\n\u001b[1;32m   3372\u001b[0m         resample\u001b[38;5;241m=\u001b[39mresample,\n\u001b[1;32m   3373\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[1;32m   3374\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m: data} \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}),\n\u001b[1;32m   3375\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3376\u001b[0m     )\n\u001b[1;32m   3377\u001b[0m     sci(__ret)\n\u001b[1;32m   3378\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m __ret\n",
      "File \u001b[0;32m~/anaconda3/envs/AI_Navigator/lib/python3.11/site-packages/matplotlib/__init__.py:1465\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1462\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m   1463\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(ax, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1464\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1465\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(ax, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mmap\u001b[39m(sanitize_sequence, args), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1467\u001b[0m     bound \u001b[38;5;241m=\u001b[39m new_sig\u001b[38;5;241m.\u001b[39mbind(ax, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1468\u001b[0m     auto_label \u001b[38;5;241m=\u001b[39m (bound\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mget(label_namer)\n\u001b[1;32m   1469\u001b[0m                   \u001b[38;5;129;01mor\u001b[39;00m bound\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(label_namer))\n",
      "File \u001b[0;32m~/anaconda3/envs/AI_Navigator/lib/python3.11/site-packages/matplotlib/axes/_axes.py:5759\u001b[0m, in \u001b[0;36mAxes.imshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5756\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m aspect \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5757\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_aspect(aspect)\n\u001b[0;32m-> 5759\u001b[0m im\u001b[38;5;241m.\u001b[39mset_data(X)\n\u001b[1;32m   5760\u001b[0m im\u001b[38;5;241m.\u001b[39mset_alpha(alpha)\n\u001b[1;32m   5761\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m im\u001b[38;5;241m.\u001b[39mget_clip_path() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5762\u001b[0m     \u001b[38;5;66;03m# image does not already have clipping set, clip to axes patch\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/AI_Navigator/lib/python3.11/site-packages/matplotlib/image.py:723\u001b[0m, in \u001b[0;36m_ImageBase.set_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(A, PIL\u001b[38;5;241m.\u001b[39mImage\u001b[38;5;241m.\u001b[39mImage):\n\u001b[1;32m    722\u001b[0m     A \u001b[38;5;241m=\u001b[39m pil_to_array(A)  \u001b[38;5;66;03m# Needed e.g. to apply png palette.\u001b[39;00m\n\u001b[0;32m--> 723\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_normalize_image_array(A)\n\u001b[1;32m    724\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_imcache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    725\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/AI_Navigator/lib/python3.11/site-packages/matplotlib/image.py:693\u001b[0m, in \u001b[0;36m_ImageBase._normalize_image_array\u001b[0;34m(A)\u001b[0m\n\u001b[1;32m    691\u001b[0m     A \u001b[38;5;241m=\u001b[39m A\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# If just (M, N, 1), assume scalar and apply colormap.\u001b[39;00m\n\u001b[1;32m    692\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (A\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m A\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m A\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m]):\n\u001b[0;32m--> 693\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mA\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for image data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    694\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m A\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m    695\u001b[0m     \u001b[38;5;66;03m# If the input data has values outside the valid range (after\u001b[39;00m\n\u001b[1;32m    696\u001b[0m     \u001b[38;5;66;03m# normalisation), we issue a warning and then clip X to the bounds\u001b[39;00m\n\u001b[1;32m    697\u001b[0m     \u001b[38;5;66;03m# - otherwise casting wraps extreme values, hiding outliers and\u001b[39;00m\n\u001b[1;32m    698\u001b[0m     \u001b[38;5;66;03m# making reliable interpretation impossible.\u001b[39;00m\n\u001b[1;32m    699\u001b[0m     high \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39missubdtype(A\u001b[38;5;241m.\u001b[39mdtype, np\u001b[38;5;241m.\u001b[39minteger) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: Invalid shape (1, 28, 28) for image data"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model.eval()\n",
    "data, target = test_data[0]\n",
    "data = data.unsqueeze(0).to(device)  # Specify the dimension to unsqueeze\n",
    "output = model(data)\n",
    "prediction = output.argmax(dim=1, keepdim=True).item()\n",
    "print(f'Prediction: {prediction}')\n",
    "image = data.squeeze(0).cpu().numpy()\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be847698-397d-4c49-b30d-227d50f54dc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
